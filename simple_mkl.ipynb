{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac85549-0f08-4e48-802b-983850a4f98c",
   "metadata": {},
   "source": [
    "### SimpleMKL Training\n",
    "\n",
    "- In scikit-learn we utilized a single kernel (radial basis function) with cross validated bandwidth (via grid search)\n",
    "\n",
    "- We now want to extend to the case of multiple kernels (linear combination of a basis set)\n",
    "\n",
    "- Inspiration in our original implementation from here \n",
    "\n",
    "     - https://github.com/qintian0321/SimpleMKL_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f1b1ae-30b7-4af0-9474-607742e21729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b577bc2-741c-4017-86a8-d592d53d66af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SimpleMKL optimization objective\n",
    "\n",
    "### Primal problem \n",
    "\n",
    "\n",
    "### Dual Problem\n",
    "\n",
    "$$\\max_\\alpha \\ \\frac{-1}{2} \\sum_{i,j} \\alpha_i \\alpha_j y_i y_j \\sum_m d_mK_m(x_i,x_j) +\\sum_i \\alpha_i$$\n",
    "\n",
    "s.t. $$\\sum_i \\alpha_i y_i=0$$ and $$C \\geq \\alpha_i \\geq 0$$\n",
    "\n",
    "\n",
    "\n",
    "- Coefficient vector $ \\alpha$ is importance of observed features on classification problem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8bc243-3187-4e66-8dda-a1a2837d2dc9",
   "metadata": {},
   "source": [
    "### Abstract Kernel Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddddd267-59ac-420c-b85d-a72235090f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel():\n",
    "    def __init__(self,kernel_type,order=None):\n",
    "        self.kernel_type=kernel_type\n",
    "        self.order=order\n",
    "    \n",
    "    def compute_kernel(self,X):\n",
    "        \n",
    "        if self.kernel_type=='linear':\n",
    "            return np.dot(X,X.T)\n",
    "        \n",
    "        if self.kernel_type=='gaussian':\n",
    "            return None\n",
    "        \n",
    "        if self.kernel_type=='polynomial':\n",
    "            return np.dot(X**self.order,X.T**self.order)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef18ca4-aa65-4a31-abe8-45f3e4ad44b5",
   "metadata": {},
   "source": [
    "### Functions for Multiple Kernel Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "01c5bd8f-769f-44dd-b990-e9e644835f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dual(X,y,kernel_list,d_m,constant,compute_gap=True):\n",
    "    \"\"\" Compute dual objective value\n",
    "    \"\"\"\n",
    "    kernel=compose_kernels(X,kernel_list,d_m)\n",
    "    single_kernel=svm.SVC(C=constant,kernel='precomputed')\n",
    "\n",
    "    single_kernel.fit(kernel,y)\n",
    "    \n",
    "    alpha=np.empty(len(y))\n",
    "    alpha[single_kernel.support_]=np.abs(single_kernel.dual_coef_[0]) \n",
    "    alpha[alpha==None]=0\n",
    "    \n",
    "    \n",
    "    J=0.5*np.dot(np.dot(alpha,kernel*y),alpha.T)+np.sum(alpha)\n",
    "    \n",
    "    if compute_gap:\n",
    "        kernel_eval=[np.dot(np.dot(np.dot(alpha,alpha.T),np.dot(y,y.T)),k_i.compute_kernel(X)) for k_i in kernel_list]\n",
    "        duality_gap=J-np.sum(alpha)+0.5*np.max(kernel_eval)\n",
    "        \n",
    "        return J,duality_gap\n",
    "    \n",
    "    return J\n",
    "\n",
    "def compose_kernels(X,kernel_list,weights):\n",
    "    \"\"\" Compute positive linear combination of kernels \n",
    "    \"\"\"\n",
    "    return np.sum(np.array([weights[ct]*k_i.compute_kernel(X) for ct,k_i in enumerate(kernel_list)]),axis=0)\n",
    "    \n",
    "def compute_gradient(kernel,X,y,alpha):\n",
    "    \"\"\" Compute gradient of MKL objective closed form \n",
    "    \"\"\"\n",
    "    kernel_mat=kernel.compute_kernel(X)\n",
    "    gradient_obj=-0.5*np.dot(np.dot(np.dot(alpha,alpha.T),np.dot(y,y.T)),kernel_mat)\n",
    "    \n",
    "    return gradient_obj\n",
    "\n",
    "\n",
    "def descent_direction(d_m,mu,grad_dm,grad_mu):\n",
    "    \"\"\" Compute direction of gradient descent \n",
    "    \n",
    "    THINK THERE IS AN ISSUE HERE \n",
    "    \"\"\"\n",
    "    if d_m==0 and grad_dm-grad_mu>0:\n",
    "        return 0\n",
    "    \n",
    "    elif d_m>0 and d_m!=mu:\n",
    "        return -grad_dm+grad_mu\n",
    "    \n",
    "    elif d_m==mu:\n",
    "        pass\n",
    "    \n",
    "def line_search(X,y,kernel_list,D,d_m,gamma_max,disc):\n",
    "    \"\"\" Selects step size to minimize obj value\n",
    "    \"\"\"\n",
    "    \n",
    "    # grid of step size begins bigger than 0\n",
    "    grid=np.arange(0+gamma_max/disc,gamma_max,gamma_max/disc)\n",
    "    \n",
    "    min_gamma,min_obj_val=None,10e8\n",
    "    for gamma_i in grid:\n",
    "        d_i=d_m+gamma_i*D\n",
    "        dual_obj_val=compute_dual(X,y,kernel_list,d_m,constant=100,compute_gap=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if abs(dual_obj_val)<abs(min_obj_val):\n",
    "            min_obj_val=dual_obj_val\n",
    "            min_gamma=gamma_i\n",
    "        \n",
    "    \n",
    "    return min_gamma\n",
    "\n",
    "def primal_dual_opt(X,y,m,kernel_type,order,gap=10e-4,maxiter=10):\n",
    "    \"\"\" X feature set, y are class outcomes\n",
    "        d_m is weight vector  on kernels, alpha is coefficient vector\n",
    "    \"\"\"\n",
    "    \n",
    "    duality_gap=1\n",
    "    C=0.1# penalization param\n",
    "    line_search_steps=5\n",
    "    n=len(y)\n",
    "    counter=0\n",
    "    \n",
    "    # optimziation init \n",
    "    d_m=np.ones(m)/m\n",
    "    D=np.ones(m)\n",
    "    \n",
    "    kernel_list=[Kernel(kernel_type,i) for i in range(1,order+1)]\n",
    "    alpha=np.zeros(n)\n",
    "    \n",
    "    # stopping criteria\n",
    "    while duality_gap>gap:\n",
    "        \n",
    "        if counter>maxiter:\n",
    "            return d_m\n",
    "        counter+=1\n",
    "        kernel=compose_kernels(X,kernel_list,d_m)\n",
    "     \n",
    "    \n",
    "        # compute svm objective\n",
    "        J_d,duality_gap=compute_dual(X,y,kernel_list,d_m,C) \n",
    "        print(duality_gap)\n",
    "        \n",
    "        \n",
    "        # gradient wrt each kernel\n",
    "        gradient_j=[compute_gradient(i,X,y,alpha) for i in kernel_list] \n",
    "        mu=np.argmax(d_m)\n",
    "        \n",
    "        J_hat=0\n",
    "        d_hat=d_m\n",
    "        D_hat=D\n",
    "        \n",
    "        \n",
    "        # descent direction\n",
    "        while J_hat<J_d: \n",
    "            \n",
    "            d_m=d_hat\n",
    "            D=D_hat\n",
    "            ratio=-d_m/D\n",
    "          \n",
    "            vu=np.argmin(ratio)\n",
    "            gamma_max=d_m[vu]/D[vu]\n",
    "            \n",
    "            \n",
    "            kernel=compose_kernels(X,kernel_list,d_m)\n",
    "            J_hat=compute_dual(X,y,kernel_list,d_m,constant=1,compute_gap=False)\n",
    "        \n",
    "            \n",
    "        # line search in descent direction  \n",
    "        gamma_step=line_search(X,y,kernel_list,D,d_m,gamma_max,disc=line_search_steps)\n",
    "        \n",
    "        d_m=(d_m+gamma_step*D)/np.sum(d_m+gamma_step*D)\n",
    "        \n",
    "        \n",
    "    return d_m\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "18d90af1-4d44-4e24-9f53-1d3aa4fcade4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n",
      "298.390694660662\n",
      "[0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "def test_mkl():\n",
    "    \n",
    "    n=50 # data set size\n",
    "    \n",
    "    m=3 # num kernels\n",
    "    \n",
    "    y=np.random.rand(n).round() # class labels\n",
    "    x=np.random.rand(n,5) # \n",
    "    kernel_type='polynomial'\n",
    "    order=3\n",
    "  \n",
    "    primal_dual_opt(x,y,m,kernel_type,order)\n",
    "    \n",
    "    \n",
    "    return\n",
    "\n",
    "test_mkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618ba28-08b4-407c-b7ce-1ae3d0b41b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
